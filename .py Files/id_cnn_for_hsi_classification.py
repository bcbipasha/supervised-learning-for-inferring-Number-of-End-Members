# -*- coding: utf-8 -*-
"""ID CNN for HSI Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fOg5ajnHzd9gjqws7e-GCQT7-chTy2Vw
"""

from keras.utils import CustomObjectScope
import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
import os
from os import listdir
import glob
import scipy.io as sio
import keras
from keras.models import Sequential
from keras.layers import Dense, Flatten, Convolution1D, Dropout, Activation
from keras.optimizers import SGD
from keras.initializers import random_uniform
from sklearn.model_selection import train_test_split
#from keras.layers.convolutional import Conv1D
from keras.models import Sequential
from keras.layers import Conv1D, Dense, MaxPool1D, Flatten, Input
from keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models

path="/content/drive/MyDrive/dataset em wise/"
import numpy as np
X=np.load(path+'X.npy')
y=np.load(path+'Y.npy')
y=y.astype('int')
nClass=6

"""AUTOENCODER"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
# X_train=tf.keras.utils.normalize(X_train,axis=1)
# X_test=tf.keras.utils.normalize(X_test,axis=1)
X_train=np.expand_dims(X_train,axis=2)
X_test=np.expand_dims(X_test,axis=2)
sequence_length=X.shape[1]
num_classes=6

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
# X_train=tf.keras.utils.normalize(X_train,axis=1)
# X_test=tf.keras.utils.normalize(X_test,axis=1)
X_train=np.expand_dims(X_train,axis=2)
X_test=np.expand_dims(X_test,axis=2)
sequence_length=X.shape[1]
num_classes=6

def create_cnn_model(input_shape, num_classes):
    model = models.Sequential([
        keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool2D(pool_size=(2,2)),
        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding="same"),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool2D(pool_size=(3,3)),
        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding="same"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding="same"),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding="same"),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPool2D(pool_size=(2,2)),
        keras.layers.Flatten(),
        keras.layers.Dense(1024,activation='relu'),
        keras.layers.Dropout(0.5),
        keras.layers.Dense(1024,activation='relu'),
        keras.layers.Dropout(0.5),
        keras.layers.Dense(10,activation='softmax')
    ])
    return model

# Define the 1D CNN model
def create_cnn_model(input_shape, num_classes):
    model = models.Sequential([
        layers.Conv1D(16, kernel_size=3, activation='tanh', input_shape=input_shape),
        layers.MaxPooling1D(pool_size=2),
        # layers.Conv1D(16, kernel_size=3, activation='tanh', input_shape=input_shape),
        # layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(32, kernel_size=3, activation='tanh', input_shape=input_shape),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(32, kernel_size=3, activation='tanh'),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(64, kernel_size=3, activation='tanh'),
        layers.MaxPooling1D(pool_size=2),
        layers.Flatten(),
        layers.Dense(64, activation='tanh'),
        layers.Dropout(0.25),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

# Create the CNN model
import tensorflow.keras.models as models
from tensorflow.keras import layers
input_shape = (sequence_length, 1)
model = create_cnn_model(input_shape, num_classes)

# Compile the model
#from tensorflow.keras.losses import CategoricalCrossentropy
#with tf.keras.utils.custom_object_scope({'crossentropy': CategoricalCrossentropy()}):

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

from tensorflow.keras.utils import plot_model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

# Train the model
history=model.fit(X_train, y_train, batch_size=32, epochs=3000, validation_data=(X_test, y_test))

# evaluate the model

# evaluate the model
_, train_acc = model.evaluate(X_train, y_train, verbose=0)
_, test_acc = model.evaluate(X_test, y_test, verbose=0)

# plot loss during training
from matplotlib import pyplot
pyplot.subplot(211)
pyplot.title('Loss')
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
# plot accuracy during training
pyplot.subplot(212)
pyplot.title('Accuracy')
pyplot.plot(history.history['accuracy'], label='train')
pyplot.plot(history.history['val_accuracy'], label='test')
pyplot.legend()
pyplot.show()

# calculating metrics for this CNN model using sklearn
from sklearn.datasets import make_circles
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from keras.models import Sequential
from keras.layers import Dense
# predict probabilities for test set
yhat_probs = model.predict(X_test, verbose=0)
# predict crisp classes for test set
#yhat_classes = model.predict_classes(X_test, verbose=0)
yhat_classes = np.argmax(model.predict(X_test), axis=1)

# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(y_test, yhat_classes)
print('Accuracy: %f' % accuracy)
# precision tp / (tp + fp)
precision = precision_score(y_test, yhat_classes,average='macro')
print('Precision: %f' % precision)
# recall: tp / (tp + fn)
recall = recall_score(y_test, yhat_classes,average='macro')
print('Recall: %f' % recall)
# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(y_test, yhat_classes,average='macro')
print('F1 score: %f' % f1)
# kappa
kappa = cohen_kappa_score(y_test, yhat_classes)
print('Cohens kappa: %f' % kappa)
# confusion matrix
matrix = confusion_matrix(y_test, yhat_classes)
print(matrix)

from sklearn.metrics import classification_report

y_pred = model.predict(X_test, batch_size=64, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)

print(classification_report(y_test, y_pred_bool))